import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from keras.layers import LSTM, Dense, Dropout
from keras.models import Sequential 
from keras.optimizers import Adam
from streamlit_option_menu import option_menu

st.set_page_config(layout="wide")

df = pd.read_csv('./csv/onion_week.csv', index_col='week', encoding="cp949")

st.sidebar.page_link('pages/cabbage.py', label='ë°°ì¶”', icon='ğŸ¥¬')
st.sidebar.page_link('pages/pepper.py', label='ê³ ì¶”', icon='ğŸŒ¶ï¸')
st.sidebar.page_link('pages/onion.py', label='ì–‘íŒŒ', icon='ğŸ§…')
st.sidebar.page_link('pages/radish.py', label='ë¬´', icon='ğŸ¤')
st.sidebar.page_link('pages/garlic.py', label='ë§ˆëŠ˜', icon='ğŸ§„')

@st.cache_resource
def train_lstm_model(data, target_column):
    
    X = data[['ìˆ˜ì…ì•¡','ìˆ˜ì…ëŸ‰', 'ë¬¼ê°€ì§€ìˆ˜', 'ê°•ìˆ˜ëŸ‰']]  
    y = data[['ì†Œë§¤ê°€']]  # ì¢…ì† ë³€ìˆ˜: ê°€ê²©

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)

    scalerX = MinMaxScaler()
    scalerX.fit(X_train)

    X_train_norm = scalerX.transform(X_train)
    X_test_norm = scalerX.transform(X_test)

    scalerY = MinMaxScaler()
    scalerY.fit(y_train)

    y_train_norm = scalerY.transform(y_train)
    y_test_norm = scalerY.transform(y_test)

    # LSTM ëª¨ë¸ êµ¬ì„±
    model = Sequential()
    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(4, 1)))
    model.add(MaxPooling1D(pool_size=1))
    model.add(Flatten())

    model.add(Dense(32, activation='tanh'))
    model.add(Dropout(0.2))  
    model.add(Dense(1))

    optimizer = Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])
    model.fit(X_train_norm, y_train_norm,
              validation_data=(X_test_norm, y_test_norm), epochs=30, batch_size=10, verbose=2)

    return model, scalerX, scalerY, X_test_norm, y_test_norm

# ì˜ˆì¸¡ í•¨ìˆ˜
def make_prediction(model, scalerX, scalerY, input_values):
    input_df = pd.DataFrame([input_values], columns=['ìˆ˜ì…ì•¡', 'ìˆ˜ì…ëŸ‰', 'ë¬¼ê°€ì§€ìˆ˜', 'ê°•ìˆ˜ëŸ‰'])
    
    scaled_input = scalerX.transform(input_df)
    prediction = model.predict(scaled_input)
    predicted_price = scalerY.inverse_transform(prediction)
    
    return predicted_price[0][0]

# ì„±ëŠ¥ í‰ê°€ í•¨ìˆ˜
def calculate_metrics(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
    return mae, rmse, mape



with st.sidebar:
    ìˆ˜ì…ì•¡ = st.slider('ìˆ˜ì…ì•¡ë¥¼ ì„ íƒí•˜ì„¸ìš”. (ë§Œì›)', float(df['ìˆ˜ì…ì•¡'].min()), float(df['ìˆ˜ì…ì•¡'].max()))
    ìˆ˜ì…ëŸ‰ = st.slider('ìˆ˜ì…ëŸ‰ì„ ì„ íƒí•˜ì„¸ìš”. (kg)', float(df['ìˆ˜ì…ëŸ‰'].min()), float(df['ìˆ˜ì…ëŸ‰'].max()))
    ë¬¼ê°€ì§€ìˆ˜ = st.slider('ì–‘íŒŒì˜ ë¬¼ê°€ì§€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.', 1, 200)
    ê°•ìˆ˜ëŸ‰ = st.slider('ì „êµ­ì˜ ê°•ìˆ˜ëŸ‰ì„ ì„ íƒí•˜ì„¸ìš”.', 1, 10)

    target_column = 'ì†Œë§¤ê°€'  # ìˆ˜ì •ëœ ë¶€ë¶„: ì†Œë§¤ê°€ ì»¬ëŸ¼ìœ¼ë¡œ ì„¤ì •
    input_values = [ìˆ˜ì…ì•¡, ìˆ˜ì…ëŸ‰, ë¬¼ê°€ì§€ìˆ˜, ê°•ìˆ˜ëŸ‰]

    # ëª¨ë¸ í›ˆë ¨ ë° ë°ì´í„° ë¶„ë¦¬
    model, scalerX, scalerY, X_test_norm, y_test_norm = train_lstm_model(df, target_column)

    if st.button('ê°€ê²© ì˜ˆì¸¡í•˜ê¸°'):
        predicted_price = make_prediction(model, scalerX, scalerY, input_values)

# ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
onion = pd.read_csv('./csv/onion_predicted.csv', encoding="cp949")
onion['week'] = pd.to_datetime(onion['week'])

st.title('5ëŒ€ ë†ì‚°ë¬¼ ì£¼ê°„ê°€ê²© ì˜ˆì¸¡ í”„ë¡œì íŠ¸')
st.markdown('-----------')
st.text('\n')
predicted_price = make_prediction(model, scalerX, scalerY, input_values)
st.header(f"ì˜ˆì¸¡ëœ ì–‘íŒŒì˜ ê°€ê²©: {predicted_price:.2f}ì›")

st.text('\n')
st.subheader('ì–‘íŒŒ ì†Œë§¤ê°€ ê·¸ë˜í”„(20)', divider='gray')
st.text('\n')

st.line_chart(
        onion,
        x="week",
        y=["Predicted Values", "actual Values"],
        color=["#D3D3D3", "#32CD32"])

# ì„±ëŠ¥ í‰ê°€ ë° ê²°ê³¼ ì¶œë ¥
y_test_inverse = scalerY.inverse_transform(y_test_norm)  # ì •ê·œí™”ëœ y_test ê°’ì„ ì—­ë³€í™˜
y_pred_inverse = model.predict(X_test_norm)  # ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’
y_pred_inverse = scalerY.inverse_transform(y_pred_inverse)  # ì˜ˆì¸¡ê°’ ì—­ë³€í™˜

mae, rmse, mape = calculate_metrics(y_test_inverse, y_pred_inverse)

# ì„±ëŠ¥ ê²°ê³¼ë¥¼ í‘œë¡œ í‘œì‹œ
metrics_data = {
    'Metric': ['MAE', 'RMSE', 'MAPE'],
    'Value': [mae, rmse, mape]
}
metrics_df = pd.DataFrame(metrics_data)
metrics_df.set_index('Metric', inplace=True)  # 'Metric' ì»¬ëŸ¼ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
metrics_df.index.name = 'Metrics'  # ì¸ë±ìŠ¤ ì´ë¦„ì„ 'Metrics'ë¡œ ì„¤ì •

st.subheader('ëª¨ë¸ ì„±ëŠ¥ í‰ê°€')
st.table(metrics_df)

    




